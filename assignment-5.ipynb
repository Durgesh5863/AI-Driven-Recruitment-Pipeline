{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel, DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('new_combined_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): DistilBertSdpaAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'ID', 'Name', 'Role', 'Transcript', 'Resume', 'decision',\n",
       "       'Reason for decision', 'Job Description', 'num_words_in_transcript',\n",
       "       'resume_jd_similarity', 'resume_transcript_similarity', 'sentiment',\n",
       "       'polarity', 'lexical_diversity', 'transcript_length',\n",
       "       'technical_skill_match', 'soft_skills_sentiment', 'resume_length',\n",
       "       'job_description_experience_match', 'cultural_fit_sentiment',\n",
       "       'job_fit_score', 'confidence_score', 'job_desc_complexity',\n",
       "       'interaction_quality', 'clarity_score', 'text_complexity_transcript',\n",
       "       'text_complexity_resume'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset for Batch Processing\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx]\n",
    "\n",
    "# Function to get embeddings batch-wise\n",
    "def generate_embeddings(texts, batch_size=32):\n",
    "    dataset = TextDataset(texts)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    embeddings = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            encoded_inputs = tokenizer(\n",
    "                list(batch), return_tensors='pt', truncation=True, padding=True, max_length=512\n",
    "            )\n",
    "            encoded_inputs = {key: val.to(device) for key, val in encoded_inputs.items()}\n",
    "            outputs = model(**encoded_inputs)\n",
    "            batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "            embeddings.append(batch_embeddings)\n",
    "\n",
    "    return np.vstack(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['Reason for decision', 'Job Description', 'polarity']\n",
    "numerical_features = [\n",
    "    'num_words_in_transcript', 'resume_jd_similarity', \n",
    "    'resume_transcript_similarity', 'sentiment',\n",
    "    'lexical_diversity', 'transcript_length', 'technical_skill_match',\n",
    "    'soft_skills_sentiment', 'resume_length',\n",
    "    'job_description_experience_match', 'cultural_fit_sentiment',\n",
    "    'job_fit_score', 'confidence_score', 'job_desc_complexity',\n",
    "    'interaction_quality', 'clarity_score', \n",
    "    'text_complexity_transcript', 'text_complexity_resume'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for Reason for decision...\n",
      "Generating embeddings for Job Description...\n",
      "Generating embeddings for polarity...\n",
      "All embeddings generated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings\n",
    "for feature in text_features:\n",
    "    print(f\"Generating embeddings for {feature}...\")\n",
    "    data[f'{feature}_embedding'] = list(generate_embeddings(data[feature].tolist()))\n",
    "\n",
    "print(\"All embeddings generated successfully.\")\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = MinMaxScaler()\n",
    "data[numerical_features] = scaler.fit_transform(data[numerical_features])\n",
    "\n",
    "# Concatenate all features\n",
    "embeddings = np.concatenate(\n",
    "    [np.vstack(data[f'{feat}_embedding'].to_numpy()) for feat in text_features] +\n",
    "    [data[numerical_features].to_numpy()], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save concatenated embeddings and features back to the dataset\n",
    "embedding_df = pd.DataFrame(\n",
    "    embeddings, \n",
    "    columns=[f\"feature_{i}\" for i in range(embeddings.shape[1])]\n",
    ")\n",
    "\n",
    "# Add the target column back for supervised learning\n",
    "embedding_df['decision'] = data['decision'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_2313</th>\n",
       "      <th>feature_2314</th>\n",
       "      <th>feature_2315</th>\n",
       "      <th>feature_2316</th>\n",
       "      <th>feature_2317</th>\n",
       "      <th>feature_2318</th>\n",
       "      <th>feature_2319</th>\n",
       "      <th>feature_2320</th>\n",
       "      <th>feature_2321</th>\n",
       "      <th>decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.179324</td>\n",
       "      <td>0.094607</td>\n",
       "      <td>-0.209987</td>\n",
       "      <td>0.082771</td>\n",
       "      <td>0.817316</td>\n",
       "      <td>-0.448502</td>\n",
       "      <td>0.083290</td>\n",
       "      <td>0.849484</td>\n",
       "      <td>-0.000335</td>\n",
       "      <td>-0.337400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.076585</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.504845</td>\n",
       "      <td>0.613356</td>\n",
       "      <td>0.772682</td>\n",
       "      <td>0.435219</td>\n",
       "      <td>0.370576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.225972</td>\n",
       "      <td>-0.208748</td>\n",
       "      <td>0.135149</td>\n",
       "      <td>0.150673</td>\n",
       "      <td>0.485873</td>\n",
       "      <td>0.055903</td>\n",
       "      <td>0.022488</td>\n",
       "      <td>0.389991</td>\n",
       "      <td>-0.174321</td>\n",
       "      <td>-0.719327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.210348</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.779988</td>\n",
       "      <td>0.768511</td>\n",
       "      <td>0.299537</td>\n",
       "      <td>0.401584</td>\n",
       "      <td>0.429927</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.049797</td>\n",
       "      <td>0.304285</td>\n",
       "      <td>-0.228528</td>\n",
       "      <td>0.102754</td>\n",
       "      <td>0.240614</td>\n",
       "      <td>0.208117</td>\n",
       "      <td>0.364976</td>\n",
       "      <td>0.522812</td>\n",
       "      <td>-0.010486</td>\n",
       "      <td>-0.389484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.072764</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.703692</td>\n",
       "      <td>0.582768</td>\n",
       "      <td>0.752163</td>\n",
       "      <td>0.312548</td>\n",
       "      <td>0.469971</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.095022</td>\n",
       "      <td>-0.180992</td>\n",
       "      <td>0.011591</td>\n",
       "      <td>0.011805</td>\n",
       "      <td>-0.035110</td>\n",
       "      <td>-0.005788</td>\n",
       "      <td>0.106368</td>\n",
       "      <td>0.139976</td>\n",
       "      <td>0.018789</td>\n",
       "      <td>-0.342472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.540741</td>\n",
       "      <td>0.164754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.372348</td>\n",
       "      <td>0.688049</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>0.414987</td>\n",
       "      <td>0.483559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.088482</td>\n",
       "      <td>0.300307</td>\n",
       "      <td>-0.178998</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.475154</td>\n",
       "      <td>0.168386</td>\n",
       "      <td>0.281142</td>\n",
       "      <td>0.566269</td>\n",
       "      <td>-0.050585</td>\n",
       "      <td>-0.304064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.060762</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.449969</td>\n",
       "      <td>0.632492</td>\n",
       "      <td>0.533092</td>\n",
       "      <td>0.440336</td>\n",
       "      <td>0.607910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>0.233737</td>\n",
       "      <td>0.078628</td>\n",
       "      <td>-0.030567</td>\n",
       "      <td>0.054535</td>\n",
       "      <td>0.193983</td>\n",
       "      <td>0.054798</td>\n",
       "      <td>0.351920</td>\n",
       "      <td>-0.021288</td>\n",
       "      <td>-0.061951</td>\n",
       "      <td>-0.344478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.516057</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.770451</td>\n",
       "      <td>0.729232</td>\n",
       "      <td>0.555623</td>\n",
       "      <td>0.399964</td>\n",
       "      <td>0.541649</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>0.231737</td>\n",
       "      <td>0.046225</td>\n",
       "      <td>-0.256670</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.293122</td>\n",
       "      <td>-0.129435</td>\n",
       "      <td>-0.024141</td>\n",
       "      <td>0.317838</td>\n",
       "      <td>-0.032955</td>\n",
       "      <td>-0.186927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.591477</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.762699</td>\n",
       "      <td>0.699965</td>\n",
       "      <td>0.303762</td>\n",
       "      <td>0.313024</td>\n",
       "      <td>0.534925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>0.297704</td>\n",
       "      <td>-0.047423</td>\n",
       "      <td>-0.014681</td>\n",
       "      <td>0.033673</td>\n",
       "      <td>0.027335</td>\n",
       "      <td>-0.071068</td>\n",
       "      <td>0.320845</td>\n",
       "      <td>-0.013860</td>\n",
       "      <td>-0.027852</td>\n",
       "      <td>-0.193233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.552929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.760098</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.533092</td>\n",
       "      <td>0.351979</td>\n",
       "      <td>0.506818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>0.332778</td>\n",
       "      <td>0.196317</td>\n",
       "      <td>-0.184458</td>\n",
       "      <td>0.044037</td>\n",
       "      <td>0.461602</td>\n",
       "      <td>-0.142836</td>\n",
       "      <td>0.100957</td>\n",
       "      <td>0.141142</td>\n",
       "      <td>-0.057379</td>\n",
       "      <td>-0.298707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.556526</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>0.740856</td>\n",
       "      <td>0.352645</td>\n",
       "      <td>0.345215</td>\n",
       "      <td>0.402437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>0.233737</td>\n",
       "      <td>0.078628</td>\n",
       "      <td>-0.030567</td>\n",
       "      <td>0.054535</td>\n",
       "      <td>0.193983</td>\n",
       "      <td>0.054798</td>\n",
       "      <td>0.351920</td>\n",
       "      <td>-0.021288</td>\n",
       "      <td>-0.061951</td>\n",
       "      <td>-0.344478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.475588</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.813596</td>\n",
       "      <td>0.748534</td>\n",
       "      <td>0.492255</td>\n",
       "      <td>0.340857</td>\n",
       "      <td>0.420292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3174 rows × 2323 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0      0.179324   0.094607  -0.209987   0.082771   0.817316  -0.448502   \n",
       "1     -0.225972  -0.208748   0.135149   0.150673   0.485873   0.055903   \n",
       "2      0.049797   0.304285  -0.228528   0.102754   0.240614   0.208117   \n",
       "3      0.095022  -0.180992   0.011591   0.011805  -0.035110  -0.005788   \n",
       "4      0.088482   0.300307  -0.178998   0.007200   0.475154   0.168386   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "3169   0.233737   0.078628  -0.030567   0.054535   0.193983   0.054798   \n",
       "3170   0.231737   0.046225  -0.256670   0.001107   0.293122  -0.129435   \n",
       "3171   0.297704  -0.047423  -0.014681   0.033673   0.027335  -0.071068   \n",
       "3172   0.332778   0.196317  -0.184458   0.044037   0.461602  -0.142836   \n",
       "3173   0.233737   0.078628  -0.030567   0.054535   0.193983   0.054798   \n",
       "\n",
       "      feature_6  feature_7  feature_8  feature_9  ...  feature_2313  \\\n",
       "0      0.083290   0.849484  -0.000335  -0.337400  ...      0.833333   \n",
       "1      0.022488   0.389991  -0.174321  -0.719327  ...      0.391667   \n",
       "2      0.364976   0.522812  -0.010486  -0.389484  ...      0.858333   \n",
       "3      0.106368   0.139976   0.018789  -0.342472  ...      0.750000   \n",
       "4      0.281142   0.566269  -0.050585  -0.304064  ...      0.725000   \n",
       "...         ...        ...        ...        ...  ...           ...   \n",
       "3169   0.351920  -0.021288  -0.061951  -0.344478  ...      0.133333   \n",
       "3170  -0.024141   0.317838  -0.032955  -0.186927  ...      0.150000   \n",
       "3171   0.320845  -0.013860  -0.027852  -0.193233  ...      0.166667   \n",
       "3172   0.100957   0.141142  -0.057379  -0.298707  ...      0.141667   \n",
       "3173   0.351920  -0.021288  -0.061951  -0.344478  ...      0.141667   \n",
       "\n",
       "      feature_2314  feature_2315  feature_2316  feature_2317  feature_2318  \\\n",
       "0         0.333333      0.076585      0.461538      0.504845      0.613356   \n",
       "1         0.333333      0.210348      0.076923      0.779988      0.768511   \n",
       "2         0.333333      0.072764      0.230769      0.703692      0.582768   \n",
       "3         0.540741      0.164754      0.000000      0.372348      0.688049   \n",
       "4         0.600000      0.060762      0.307692      0.449969      0.632492   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "3169      0.333333      0.516057      0.153846      0.770451      0.729232   \n",
       "3170      0.333333      0.591477      0.307692      0.762699      0.699965   \n",
       "3171      0.500000      0.552929      0.000000      0.760098      0.803279   \n",
       "3172      0.333333      0.556526      0.076923      0.767901      0.740856   \n",
       "3173      0.333333      0.475588      0.076923      0.813596      0.748534   \n",
       "\n",
       "      feature_2319  feature_2320  feature_2321  decision  \n",
       "0         0.772682      0.435219      0.370576         0  \n",
       "1         0.299537      0.401584      0.429927         1  \n",
       "2         0.752163      0.312548      0.469971         0  \n",
       "3         0.543351      0.414987      0.483559         1  \n",
       "4         0.533092      0.440336      0.607910         0  \n",
       "...            ...           ...           ...       ...  \n",
       "3169      0.555623      0.399964      0.541649         1  \n",
       "3170      0.303762      0.313024      0.534925         0  \n",
       "3171      0.533092      0.351979      0.506818         1  \n",
       "3172      0.352645      0.345215      0.402437         0  \n",
       "3173      0.492255      0.340857      0.420292         0  \n",
       "\n",
       "[3174 rows x 2323 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "\n",
    "# Encode target variable\n",
    "y = data['decision']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial completed - Accuracy: 0.8882, ROC-AUC: 0.8883\n",
      "Trial completed - Accuracy: 0.8866, ROC-AUC: 0.8868\n",
      "Trial completed - Accuracy: 0.8850, ROC-AUC: 0.8852\n",
      "Trial completed - Accuracy: 0.8709, ROC-AUC: 0.8711\n",
      "Trial completed - Accuracy: 0.8850, ROC-AUC: 0.8851\n",
      "Trial completed - Accuracy: 0.8850, ROC-AUC: 0.8852\n",
      "Trial completed - Accuracy: 0.8835, ROC-AUC: 0.8836\n",
      "Trial completed - Accuracy: 0.8850, ROC-AUC: 0.8852\n",
      "Trial completed - Accuracy: 0.8835, ROC-AUC: 0.8836\n",
      "Trial completed - Accuracy: 0.8835, ROC-AUC: 0.8836\n",
      "\n",
      "Best parameters: {'max_depth': 10, 'learning_rate': 0.12884503793747262, 'n_estimators': 556, 'subsample': 0.5138162711002101, 'colsample_bytree': 0.6670832638580284, 'gamma': 0.6181850881559919, 'reg_alpha': 5.205493132063401, 'reg_lambda': 3.9857976272211437}\n",
      "Best ROC-AUC score: 0.8883278441331693\n"
     ]
    }
   ],
   "source": [
    "# Suppress Optuna logs\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Define the objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "    }\n",
    "\n",
    "    # Silent training with verbose=0\n",
    "    model = xgb.XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss', verbosity=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    roc_auc = roc_auc_score(y_test, preds)\n",
    "\n",
    "    # Print ROC and AUC score for the current trial\n",
    "    print(f\"Trial completed - Accuracy: {accuracy:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "    return roc_auc  # Optimize for AUC\n",
    "\n",
    "# Run the study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Print the best parameters and AUC\n",
    "print(\"\\nBest parameters:\", study.best_params)\n",
    "print(\"Best ROC-AUC score:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 10, 'learning_rate': 0.12884503793747262, 'n_estimators': 556, 'subsample': 0.5138162711002101, 'colsample_bytree': 0.6670832638580284, 'gamma': 0.6181850881559919, 'reg_alpha': 5.205493132063401, 'reg_lambda': 3.9857976272211437}\n"
     ]
    }
   ],
   "source": [
    "# Best parameters and final model training\n",
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Durgesh Babu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:22:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-9 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-9 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-9 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-9 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-9 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-9 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6670832638580284, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, feature_types=None,\n",
       "              gamma=0.6181850881559919, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.12884503793747262,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=556, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6670832638580284, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, feature_types=None,\n",
       "              gamma=0.6181850881559919, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.12884503793747262,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=556, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6670832638580284, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='logloss', feature_types=None,\n",
       "              gamma=0.6181850881559919, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.12884503793747262,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=556, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = xgb.XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss')\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8881889763779528\n",
      "ROC_AUC: 0.8883278441331693\n"
     ]
    }
   ],
   "source": [
    "# Predictions and evaluation\n",
    "y_pred = final_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"ROC_AUC:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_classes = final_model.predict_proba(X_test)\n",
    "y_test_pred_xgb_distil = np.argmax(y_test_pred_classes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset for efficient DataLoader usage\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx]\n",
    "\n",
    "# Function to generate embeddings using CLS Token Pooling with SBERT\n",
    "def generate_embeddings(texts, model_name='all-MiniLM-L6-v2', batch_size=32, max_length=512):\n",
    "    \"\"\"\n",
    "    Generates embeddings using Sentence Transformers with CLS token pooling.\n",
    "    Args:\n",
    "        texts (list): List of texts to embed.\n",
    "        model_name (str): Pre-trained SentenceTransformer model.\n",
    "        batch_size (int): Batch size for embedding generation.\n",
    "        max_length (int): Maximum token length for each text.\n",
    "    Returns:\n",
    "        np.ndarray: Generated embeddings.\n",
    "    \"\"\"\n",
    "    # Load the SentenceTransformer model\n",
    "    model = SentenceTransformer(model_name)\n",
    "    model.max_seq_length = max_length  # Adjust max token length\n",
    "\n",
    "    # Dataset and DataLoader for batch processing\n",
    "    dataset = TextDataset(texts)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    embeddings = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Tokenize and encode with CLS token pooling\n",
    "            batch_embeddings = model.encode(\n",
    "                batch, \n",
    "                batch_size=batch_size,\n",
    "                convert_to_tensor=True,\n",
    "                show_progress_bar=False,\n",
    "                normalize_embeddings=True  # Ensures cosine similarity compatibility\n",
    "            )\n",
    "            embeddings.append(batch_embeddings.cpu().numpy())\n",
    "\n",
    "    return np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['Reason for decision', 'Job Description', 'polarity']\n",
    "numerical_features = [\n",
    "    'num_words_in_transcript', 'resume_jd_similarity', \n",
    "    'resume_transcript_similarity', 'sentiment',\n",
    "    'lexical_diversity', 'transcript_length', 'technical_skill_match',\n",
    "    'soft_skills_sentiment', 'resume_length',\n",
    "    'job_description_experience_match', 'cultural_fit_sentiment',\n",
    "    'job_fit_score', 'confidence_score', 'job_desc_complexity',\n",
    "    'interaction_quality', 'clarity_score', \n",
    "    'text_complexity_transcript', 'text_complexity_resume'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for Reason for decision...\n",
      "Generating embeddings for Job Description...\n",
      "Generating embeddings for polarity...\n",
      "All embeddings generated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings\n",
    "for feature in text_features:\n",
    "    print(f\"Generating embeddings for {feature}...\")\n",
    "    data[f'{feature}_embedding'] = list(generate_embeddings(data[feature].tolist()))\n",
    "\n",
    "print(\"All embeddings generated successfully.\")\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = MinMaxScaler()\n",
    "data[numerical_features] = scaler.fit_transform(data[numerical_features])\n",
    "\n",
    "# Concatenate all features\n",
    "embeddings1 = np.concatenate(\n",
    "    [np.vstack(data[f'{feat}_embedding'].to_numpy()) for feat in text_features] +\n",
    "    [data[numerical_features].to_numpy()], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save concatenated embeddings and features back to the dataset\n",
    "embedding_df1 = pd.DataFrame(\n",
    "    embeddings1, \n",
    "    columns=[f\"feature_{i}\" for i in range(embeddings1.shape[1])]\n",
    ")\n",
    "\n",
    "# Add the target column back for supervised learning\n",
    "embedding_df1['decision'] = data['decision'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_1161</th>\n",
       "      <th>feature_1162</th>\n",
       "      <th>feature_1163</th>\n",
       "      <th>feature_1164</th>\n",
       "      <th>feature_1165</th>\n",
       "      <th>feature_1166</th>\n",
       "      <th>feature_1167</th>\n",
       "      <th>feature_1168</th>\n",
       "      <th>feature_1169</th>\n",
       "      <th>decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.040162</td>\n",
       "      <td>-0.017108</td>\n",
       "      <td>-0.045824</td>\n",
       "      <td>-0.001299</td>\n",
       "      <td>0.042042</td>\n",
       "      <td>-0.049487</td>\n",
       "      <td>-0.006759</td>\n",
       "      <td>-0.037472</td>\n",
       "      <td>-0.010179</td>\n",
       "      <td>-0.061392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.076585</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.504845</td>\n",
       "      <td>0.613356</td>\n",
       "      <td>0.772682</td>\n",
       "      <td>0.435219</td>\n",
       "      <td>0.370576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068834</td>\n",
       "      <td>0.011094</td>\n",
       "      <td>-0.033867</td>\n",
       "      <td>-0.043404</td>\n",
       "      <td>0.028510</td>\n",
       "      <td>-0.001021</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.019694</td>\n",
       "      <td>-0.009958</td>\n",
       "      <td>0.027810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.210348</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.779988</td>\n",
       "      <td>0.768511</td>\n",
       "      <td>0.299537</td>\n",
       "      <td>0.401584</td>\n",
       "      <td>0.429927</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.102072</td>\n",
       "      <td>-0.001394</td>\n",
       "      <td>0.055262</td>\n",
       "      <td>0.090628</td>\n",
       "      <td>-0.005320</td>\n",
       "      <td>-0.061961</td>\n",
       "      <td>0.004546</td>\n",
       "      <td>0.049599</td>\n",
       "      <td>0.011135</td>\n",
       "      <td>-0.049618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.072764</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.703692</td>\n",
       "      <td>0.582768</td>\n",
       "      <td>0.752163</td>\n",
       "      <td>0.312548</td>\n",
       "      <td>0.469971</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.037205</td>\n",
       "      <td>0.082585</td>\n",
       "      <td>-0.006266</td>\n",
       "      <td>0.015953</td>\n",
       "      <td>-0.021017</td>\n",
       "      <td>-0.007450</td>\n",
       "      <td>0.005732</td>\n",
       "      <td>-0.063339</td>\n",
       "      <td>-0.065506</td>\n",
       "      <td>-0.040845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.540741</td>\n",
       "      <td>0.164754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.372348</td>\n",
       "      <td>0.688049</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>0.414987</td>\n",
       "      <td>0.483559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.063624</td>\n",
       "      <td>-0.021584</td>\n",
       "      <td>0.045728</td>\n",
       "      <td>0.059596</td>\n",
       "      <td>0.067983</td>\n",
       "      <td>-0.040720</td>\n",
       "      <td>-0.034877</td>\n",
       "      <td>0.012269</td>\n",
       "      <td>0.008448</td>\n",
       "      <td>-0.004602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.060762</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.449969</td>\n",
       "      <td>0.632492</td>\n",
       "      <td>0.533092</td>\n",
       "      <td>0.440336</td>\n",
       "      <td>0.607910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>-0.004482</td>\n",
       "      <td>0.006377</td>\n",
       "      <td>-0.001969</td>\n",
       "      <td>0.027536</td>\n",
       "      <td>0.059272</td>\n",
       "      <td>0.013968</td>\n",
       "      <td>0.021843</td>\n",
       "      <td>0.012360</td>\n",
       "      <td>-0.031767</td>\n",
       "      <td>-0.085682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.516057</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.770451</td>\n",
       "      <td>0.729232</td>\n",
       "      <td>0.555623</td>\n",
       "      <td>0.399964</td>\n",
       "      <td>0.541649</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>-0.041130</td>\n",
       "      <td>0.039581</td>\n",
       "      <td>-0.000266</td>\n",
       "      <td>-0.037578</td>\n",
       "      <td>-0.073201</td>\n",
       "      <td>0.051874</td>\n",
       "      <td>0.152850</td>\n",
       "      <td>-0.010868</td>\n",
       "      <td>0.022315</td>\n",
       "      <td>-0.046826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.591477</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.762699</td>\n",
       "      <td>0.699965</td>\n",
       "      <td>0.303762</td>\n",
       "      <td>0.313024</td>\n",
       "      <td>0.534925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>0.050766</td>\n",
       "      <td>0.094263</td>\n",
       "      <td>-0.019963</td>\n",
       "      <td>0.043912</td>\n",
       "      <td>0.015446</td>\n",
       "      <td>-0.005203</td>\n",
       "      <td>0.037215</td>\n",
       "      <td>-0.071231</td>\n",
       "      <td>-0.046503</td>\n",
       "      <td>-0.045416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.552929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.760098</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.533092</td>\n",
       "      <td>0.351979</td>\n",
       "      <td>0.506818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>-0.002540</td>\n",
       "      <td>0.007101</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>-0.082722</td>\n",
       "      <td>-0.019490</td>\n",
       "      <td>0.161442</td>\n",
       "      <td>0.091036</td>\n",
       "      <td>-0.031743</td>\n",
       "      <td>0.054705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.556526</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>0.740856</td>\n",
       "      <td>0.352645</td>\n",
       "      <td>0.345215</td>\n",
       "      <td>0.402437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>-0.004482</td>\n",
       "      <td>0.006377</td>\n",
       "      <td>-0.001969</td>\n",
       "      <td>0.027536</td>\n",
       "      <td>0.059272</td>\n",
       "      <td>0.013968</td>\n",
       "      <td>0.021843</td>\n",
       "      <td>0.012360</td>\n",
       "      <td>-0.031767</td>\n",
       "      <td>-0.085682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.475588</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.813596</td>\n",
       "      <td>0.748534</td>\n",
       "      <td>0.492255</td>\n",
       "      <td>0.340857</td>\n",
       "      <td>0.420292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3174 rows × 1171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0     -0.040162  -0.017108  -0.045824  -0.001299   0.042042  -0.049487   \n",
       "1      0.068834   0.011094  -0.033867  -0.043404   0.028510  -0.001021   \n",
       "2      0.102072  -0.001394   0.055262   0.090628  -0.005320  -0.061961   \n",
       "3      0.037205   0.082585  -0.006266   0.015953  -0.021017  -0.007450   \n",
       "4      0.063624  -0.021584   0.045728   0.059596   0.067983  -0.040720   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "3169  -0.004482   0.006377  -0.001969   0.027536   0.059272   0.013968   \n",
       "3170  -0.041130   0.039581  -0.000266  -0.037578  -0.073201   0.051874   \n",
       "3171   0.050766   0.094263  -0.019963   0.043912   0.015446  -0.005203   \n",
       "3172  -0.002540   0.007101   0.002338   0.001370  -0.082722  -0.019490   \n",
       "3173  -0.004482   0.006377  -0.001969   0.027536   0.059272   0.013968   \n",
       "\n",
       "      feature_6  feature_7  feature_8  feature_9  ...  feature_1161  \\\n",
       "0     -0.006759  -0.037472  -0.010179  -0.061392  ...      0.833333   \n",
       "1      0.003934   0.019694  -0.009958   0.027810  ...      0.391667   \n",
       "2      0.004546   0.049599   0.011135  -0.049618  ...      0.858333   \n",
       "3      0.005732  -0.063339  -0.065506  -0.040845  ...      0.750000   \n",
       "4     -0.034877   0.012269   0.008448  -0.004602  ...      0.725000   \n",
       "...         ...        ...        ...        ...  ...           ...   \n",
       "3169   0.021843   0.012360  -0.031767  -0.085682  ...      0.133333   \n",
       "3170   0.152850  -0.010868   0.022315  -0.046826  ...      0.150000   \n",
       "3171   0.037215  -0.071231  -0.046503  -0.045416  ...      0.166667   \n",
       "3172   0.161442   0.091036  -0.031743   0.054705  ...      0.141667   \n",
       "3173   0.021843   0.012360  -0.031767  -0.085682  ...      0.141667   \n",
       "\n",
       "      feature_1162  feature_1163  feature_1164  feature_1165  feature_1166  \\\n",
       "0         0.333333      0.076585      0.461538      0.504845      0.613356   \n",
       "1         0.333333      0.210348      0.076923      0.779988      0.768511   \n",
       "2         0.333333      0.072764      0.230769      0.703692      0.582768   \n",
       "3         0.540741      0.164754      0.000000      0.372348      0.688049   \n",
       "4         0.600000      0.060762      0.307692      0.449969      0.632492   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "3169      0.333333      0.516057      0.153846      0.770451      0.729232   \n",
       "3170      0.333333      0.591477      0.307692      0.762699      0.699965   \n",
       "3171      0.500000      0.552929      0.000000      0.760098      0.803279   \n",
       "3172      0.333333      0.556526      0.076923      0.767901      0.740856   \n",
       "3173      0.333333      0.475588      0.076923      0.813596      0.748534   \n",
       "\n",
       "      feature_1167  feature_1168  feature_1169  decision  \n",
       "0         0.772682      0.435219      0.370576         0  \n",
       "1         0.299537      0.401584      0.429927         1  \n",
       "2         0.752163      0.312548      0.469971         0  \n",
       "3         0.543351      0.414987      0.483559         1  \n",
       "4         0.533092      0.440336      0.607910         0  \n",
       "...            ...           ...           ...       ...  \n",
       "3169      0.555623      0.399964      0.541649         1  \n",
       "3170      0.303762      0.313024      0.534925         0  \n",
       "3171      0.533092      0.351979      0.506818         1  \n",
       "3172      0.352645      0.345215      0.402437         0  \n",
       "3173      0.492255      0.340857      0.420292         0  \n",
       "\n",
       "[3174 rows x 1171 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target variable\n",
    "y = data['decision']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings1, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial completed - Accuracy: 0.8772, ROC-AUC: 0.8773\n",
      "Trial completed - Accuracy: 0.8803, ROC-AUC: 0.8804\n",
      "Trial completed - Accuracy: 0.8787, ROC-AUC: 0.8788\n",
      "Trial completed - Accuracy: 0.9008, ROC-AUC: 0.9009\n",
      "Trial completed - Accuracy: 0.8803, ROC-AUC: 0.8804\n",
      "Trial completed - Accuracy: 0.8976, ROC-AUC: 0.8977\n",
      "Trial completed - Accuracy: 0.8913, ROC-AUC: 0.8914\n",
      "Trial completed - Accuracy: 0.8929, ROC-AUC: 0.8930\n",
      "Trial completed - Accuracy: 0.8882, ROC-AUC: 0.8883\n",
      "Trial completed - Accuracy: 0.8913, ROC-AUC: 0.8915\n",
      "\n",
      "Best parameters: {'max_depth': 3, 'learning_rate': 0.2661074821620344, 'n_estimators': 950, 'subsample': 0.9340447046791226, 'colsample_bytree': 0.6817068107732505, 'gamma': 1.1716834893600607, 'reg_alpha': 3.3676825424830605, 'reg_lambda': 6.966601507154071}\n",
      "Best ROC-AUC score: 0.9008819094480378\n"
     ]
    }
   ],
   "source": [
    "# Suppress Optuna logs\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Define the objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "    }\n",
    "\n",
    "    # Silent training with verbose=0\n",
    "    model = xgb.XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss', verbosity=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    roc_auc = roc_auc_score(y_test, preds)\n",
    "\n",
    "    # Print ROC and AUC score for the current trial\n",
    "    print(f\"Trial completed - Accuracy: {accuracy:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "    return roc_auc  # Optimize for AUC\n",
    "\n",
    "# Run the study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Print the best parameters and AUC\n",
    "print(\"\\nBest parameters:\", study.best_params)\n",
    "print(\"Best ROC-AUC score:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Durgesh Babu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:45:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-10 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-10 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-10 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-10 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-10 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-10 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6817068107732505, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, feature_types=None,\n",
       "              gamma=1.1716834893600607, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2661074821620344,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=950, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6817068107732505, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, feature_types=None,\n",
       "              gamma=1.1716834893600607, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2661074821620344,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=950, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6817068107732505, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='logloss', feature_types=None,\n",
       "              gamma=1.1716834893600607, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2661074821620344,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=950, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "final_model2 = xgb.XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss')\n",
    "final_model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9007874015748032\n",
      "ROC_AUC: 0.9008819094480378\n"
     ]
    }
   ],
   "source": [
    "# Predictions and evaluation\n",
    "y_pred = final_model2.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"ROC_AUC:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_classes = final_model2.predict_proba(X_test)\n",
    "y_test_pred_xgb_sen= np.argmax(y_test_pred_classes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Durgesh Babu\\AppData\\Local\\Temp\\ipykernel_11308\\2231157618.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'units_1': 32, 'dropout_1': 0.30000000000000004, 'units_2': 64, 'dropout_2': 0.4, 'learning_rate': 0.001377913632373173}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Function to create and train the model for Optuna optimization\n",
    "def objective(trial):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Hyperparameter tuning for number of units and layers\n",
    "    units_1 = trial.suggest_int('units_1', 32, 256, step=32)\n",
    "    dropout_1 = trial.suggest_float('dropout_1', 0.2, 0.5, step=0.1)\n",
    "    units_2 = trial.suggest_int('units_2', 32, 128, step=32)\n",
    "    dropout_2 = trial.suggest_float('dropout_2', 0.2, 0.5, step=0.1)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
    "    \n",
    "    # Build the model\n",
    "    model.add(Dense(units=units_1, activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dropout(rate=dropout_1))\n",
    "    model.add(Dense(units=units_2, activation='relu'))\n",
    "    model.add(Dropout(rate=dropout_2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=16, validation_data=(X_test, y_test), verbose=0)\n",
    "    \n",
    "    # Evaluate the model on validation data\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return score[1]  # Return validation accuracy\n",
    "\n",
    "# Create an Optuna study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Get the best parameters and train the final model\n",
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.4315 - accuracy: 0.7987 - val_loss: 0.2211 - val_accuracy: 0.8772\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.2051 - accuracy: 0.8885 - val_loss: 0.1658 - val_accuracy: 0.8945\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1710 - accuracy: 0.8944 - val_loss: 0.1622 - val_accuracy: 0.8835\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1665 - accuracy: 0.8881 - val_loss: 0.1608 - val_accuracy: 0.8882\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1607 - accuracy: 0.8901 - val_loss: 0.1569 - val_accuracy: 0.9024\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1585 - accuracy: 0.8933 - val_loss: 0.1641 - val_accuracy: 0.8740\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1577 - accuracy: 0.8988 - val_loss: 0.1578 - val_accuracy: 0.8803\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1578 - accuracy: 0.8960 - val_loss: 0.1586 - val_accuracy: 0.8787\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1577 - accuracy: 0.9004 - val_loss: 0.1596 - val_accuracy: 0.8835\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1631 - accuracy: 0.8893 - val_loss: 0.1579 - val_accuracy: 0.8913\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1572 - accuracy: 0.9004 - val_loss: 0.1849 - val_accuracy: 0.8835\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1560 - accuracy: 0.9047 - val_loss: 0.1583 - val_accuracy: 0.8787\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1601 - accuracy: 0.8937 - val_loss: 0.1608 - val_accuracy: 0.8724\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1552 - accuracy: 0.8933 - val_loss: 0.1596 - val_accuracy: 0.8756\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1566 - accuracy: 0.8925 - val_loss: 0.1593 - val_accuracy: 0.8866\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1546 - accuracy: 0.8996 - val_loss: 0.1660 - val_accuracy: 0.8835\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1522 - accuracy: 0.8944 - val_loss: 0.1586 - val_accuracy: 0.8913\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1539 - accuracy: 0.8988 - val_loss: 0.1650 - val_accuracy: 0.8882\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1531 - accuracy: 0.8988 - val_loss: 0.1640 - val_accuracy: 0.8724\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1555 - accuracy: 0.8992 - val_loss: 0.1635 - val_accuracy: 0.8740\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.1534 - accuracy: 0.8968 - val_loss: 0.1622 - val_accuracy: 0.8850\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1538 - accuracy: 0.8944 - val_loss: 0.1738 - val_accuracy: 0.8803\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1551 - accuracy: 0.8976 - val_loss: 0.1652 - val_accuracy: 0.8850\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1523 - accuracy: 0.9015 - val_loss: 0.1724 - val_accuracy: 0.8803\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1542 - accuracy: 0.8956 - val_loss: 0.1580 - val_accuracy: 0.8929\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1505 - accuracy: 0.9035 - val_loss: 0.1622 - val_accuracy: 0.8929\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1533 - accuracy: 0.8964 - val_loss: 0.1583 - val_accuracy: 0.8803\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1539 - accuracy: 0.8976 - val_loss: 0.1621 - val_accuracy: 0.8898\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1521 - accuracy: 0.9015 - val_loss: 0.1644 - val_accuracy: 0.8803\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1545 - accuracy: 0.9035 - val_loss: 0.1647 - val_accuracy: 0.8835\n",
      "Epoch 31/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1522 - accuracy: 0.8984 - val_loss: 0.1631 - val_accuracy: 0.8803\n",
      "Epoch 32/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1530 - accuracy: 0.8996 - val_loss: 0.1579 - val_accuracy: 0.8850\n",
      "Epoch 33/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.8984 - val_loss: 0.1603 - val_accuracy: 0.8992\n",
      "Epoch 34/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1509 - accuracy: 0.8996 - val_loss: 0.1649 - val_accuracy: 0.8913\n",
      "Epoch 35/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1510 - accuracy: 0.9082 - val_loss: 0.1657 - val_accuracy: 0.8709\n",
      "Epoch 36/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9004 - val_loss: 0.1733 - val_accuracy: 0.8787\n",
      "Epoch 37/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1490 - accuracy: 0.9031 - val_loss: 0.1680 - val_accuracy: 0.8803\n",
      "Epoch 38/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1516 - accuracy: 0.8960 - val_loss: 0.1633 - val_accuracy: 0.8819\n",
      "Epoch 39/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.8992 - val_loss: 0.1687 - val_accuracy: 0.8803\n",
      "Epoch 40/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1538 - accuracy: 0.8937 - val_loss: 0.1616 - val_accuracy: 0.8740\n",
      "Epoch 41/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1516 - accuracy: 0.9039 - val_loss: 0.1640 - val_accuracy: 0.8929\n",
      "Epoch 42/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.8929 - val_loss: 0.1632 - val_accuracy: 0.8882\n",
      "Epoch 43/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9078 - val_loss: 0.1612 - val_accuracy: 0.8803\n",
      "Epoch 44/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1509 - accuracy: 0.9035 - val_loss: 0.1610 - val_accuracy: 0.8787\n",
      "Epoch 45/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1524 - accuracy: 0.8968 - val_loss: 0.1578 - val_accuracy: 0.8772\n",
      "Epoch 46/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1512 - accuracy: 0.9071 - val_loss: 0.1608 - val_accuracy: 0.8882\n",
      "Epoch 47/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9039 - val_loss: 0.1619 - val_accuracy: 0.8772\n",
      "Epoch 48/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1511 - accuracy: 0.9023 - val_loss: 0.1606 - val_accuracy: 0.8803\n",
      "Epoch 49/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1541 - accuracy: 0.9019 - val_loss: 0.1610 - val_accuracy: 0.8850\n",
      "Epoch 50/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1538 - accuracy: 0.9047 - val_loss: 0.1613 - val_accuracy: 0.8819\n",
      "Epoch 51/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1512 - accuracy: 0.9000 - val_loss: 0.1624 - val_accuracy: 0.8866\n",
      "Epoch 52/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1504 - accuracy: 0.9004 - val_loss: 0.1589 - val_accuracy: 0.8850\n",
      "Epoch 53/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.8956 - val_loss: 0.1613 - val_accuracy: 0.8850\n",
      "Epoch 54/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 0.9059 - val_loss: 0.1608 - val_accuracy: 0.8835\n",
      "Epoch 55/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9004 - val_loss: 0.1649 - val_accuracy: 0.8850\n",
      "Epoch 56/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9114 - val_loss: 0.1601 - val_accuracy: 0.8850\n",
      "Epoch 57/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9051 - val_loss: 0.1593 - val_accuracy: 0.8835\n",
      "Epoch 58/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9059 - val_loss: 0.1606 - val_accuracy: 0.8866\n",
      "Epoch 59/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1500 - accuracy: 0.9035 - val_loss: 0.1647 - val_accuracy: 0.8819\n",
      "Epoch 60/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9047 - val_loss: 0.1663 - val_accuracy: 0.8961\n",
      "Epoch 61/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.9063 - val_loss: 0.1577 - val_accuracy: 0.9118\n",
      "Epoch 62/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1499 - accuracy: 0.8976 - val_loss: 0.1578 - val_accuracy: 0.9008\n",
      "Epoch 63/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 0.9059 - val_loss: 0.1644 - val_accuracy: 0.8945\n",
      "Epoch 64/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1463 - accuracy: 0.9071 - val_loss: 0.1601 - val_accuracy: 0.8976\n",
      "Epoch 65/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9090 - val_loss: 0.1596 - val_accuracy: 0.8850\n",
      "Epoch 66/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1463 - accuracy: 0.8972 - val_loss: 0.1630 - val_accuracy: 0.8819\n",
      "Epoch 67/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.8984 - val_loss: 0.1704 - val_accuracy: 0.8803\n",
      "Epoch 68/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9055 - val_loss: 0.1609 - val_accuracy: 0.8866\n",
      "Epoch 69/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9039 - val_loss: 0.1593 - val_accuracy: 0.8882\n",
      "Epoch 70/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1422 - accuracy: 0.8996 - val_loss: 0.1607 - val_accuracy: 0.9008\n",
      "Epoch 71/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9000 - val_loss: 0.1681 - val_accuracy: 0.8961\n",
      "Epoch 72/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9086 - val_loss: 0.1602 - val_accuracy: 0.9024\n",
      "Epoch 73/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9106 - val_loss: 0.1587 - val_accuracy: 0.8992\n",
      "Epoch 74/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9094 - val_loss: 0.1680 - val_accuracy: 0.8961\n",
      "Epoch 75/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.8984 - val_loss: 0.1684 - val_accuracy: 0.9008\n",
      "Epoch 76/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1419 - accuracy: 0.9074 - val_loss: 0.1598 - val_accuracy: 0.8976\n",
      "Epoch 77/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9098 - val_loss: 0.1601 - val_accuracy: 0.9024\n",
      "Epoch 78/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9043 - val_loss: 0.1599 - val_accuracy: 0.9039\n",
      "Epoch 79/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9074 - val_loss: 0.1604 - val_accuracy: 0.9118\n",
      "Epoch 80/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9082 - val_loss: 0.1596 - val_accuracy: 0.8882\n",
      "Epoch 81/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1437 - accuracy: 0.9031 - val_loss: 0.1588 - val_accuracy: 0.8866\n",
      "Epoch 82/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9098 - val_loss: 0.1576 - val_accuracy: 0.8882\n",
      "Epoch 83/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1504 - accuracy: 0.9039 - val_loss: 0.1615 - val_accuracy: 0.8835\n",
      "Epoch 84/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9078 - val_loss: 0.1597 - val_accuracy: 0.8835\n",
      "Epoch 85/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.9141 - val_loss: 0.1576 - val_accuracy: 0.9024\n",
      "Epoch 86/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9122 - val_loss: 0.1575 - val_accuracy: 0.9039\n",
      "Epoch 87/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9078 - val_loss: 0.1758 - val_accuracy: 0.8913\n",
      "Epoch 88/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9059 - val_loss: 0.1610 - val_accuracy: 0.9008\n",
      "Epoch 89/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9137 - val_loss: 0.1687 - val_accuracy: 0.8992\n",
      "Epoch 90/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1420 - accuracy: 0.9094 - val_loss: 0.1632 - val_accuracy: 0.9055\n",
      "Epoch 91/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.8960 - val_loss: 0.1590 - val_accuracy: 0.8976\n",
      "Epoch 92/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1494 - accuracy: 0.9019 - val_loss: 0.1623 - val_accuracy: 0.8772\n",
      "Epoch 93/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9094 - val_loss: 0.1631 - val_accuracy: 0.8913\n",
      "Epoch 94/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1408 - accuracy: 0.9090 - val_loss: 0.1707 - val_accuracy: 0.8882\n",
      "Epoch 95/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1369 - accuracy: 0.9145 - val_loss: 0.1670 - val_accuracy: 0.9008\n",
      "Epoch 96/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1421 - accuracy: 0.9118 - val_loss: 0.1579 - val_accuracy: 0.9087\n",
      "Epoch 97/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1425 - accuracy: 0.9137 - val_loss: 0.1666 - val_accuracy: 0.8945\n",
      "Epoch 98/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1416 - accuracy: 0.9051 - val_loss: 0.1589 - val_accuracy: 0.9118\n",
      "Epoch 99/100\n",
      "159/159 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9063 - val_loss: 0.1567 - val_accuracy: 0.8866\n",
      "Epoch 100/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.1416 - accuracy: 0.9118 - val_loss: 0.1780 - val_accuracy: 0.8835\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1780 - accuracy: 0.8835\n",
      "Final Model Test Accuracy: 0.8835\n"
     ]
    }
   ],
   "source": [
    "# Final model using the best parameters\n",
    "final_model1 = Sequential()\n",
    "final_model1.add(Dense(units=best_params['units_1'], activation='relu', input_dim=X_train.shape[1]))\n",
    "final_model1.add(Dropout(rate=best_params['dropout_1']))\n",
    "final_model1.add(Dense(units=best_params['units_2'], activation='relu'))\n",
    "final_model1.add(Dropout(rate=best_params['dropout_2']))\n",
    "final_model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "final_model1.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), \n",
    "                    loss='binary_crossentropy', \n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# Train the final model\n",
    "final_model1.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the final model\n",
    "final_accuracy = final_model1.evaluate(X_test, y_test)\n",
    "print(f\"Final Model Test Accuracy: {final_accuracy[1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_nn = final_model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()\n",
    "test_df['actual'] = y_test\n",
    "test_df['xg_distil_bert'] = y_test_pred_xgb_distil\n",
    "test_df['xg_sen_transformer'] = y_test_pred_xgb_sen\n",
    "test_df['nn_prediction'] = y_test_pred_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>xg_distil_bert</th>\n",
       "      <th>xg_sen_transformer</th>\n",
       "      <th>nn_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.889574e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.208729e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.052493e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.498156e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.075190e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.212544e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.450576e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>635 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual  xg_distil_bert  xg_sen_transformer  nn_prediction\n",
       "2270       1               1                   1   1.000000e+00\n",
       "442        1               1                   1   1.000000e+00\n",
       "2885       1               1                   1   1.000000e+00\n",
       "1655       1               0                   1   3.889574e-01\n",
       "1001       0               0                   0   4.208729e-22\n",
       "...      ...             ...                 ...            ...\n",
       "282        0               0                   0   1.052493e-18\n",
       "1953       1               1                   1   3.498156e-01\n",
       "691        0               0                   0   8.075190e-19\n",
       "794        0               0                   0   6.212544e-19\n",
       "3013       0               1                   1   6.450576e-01\n",
       "\n",
       "[635 rows x 4 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Metrics: {'Accuracy': 0.8960629921259843, 'Precision': 0.9259259259259259, 'Recall': 0.8620689655172413, 'F1-Score': 0.8928571428571429, 'ROC-AUC': 0.8962243561763422}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1-Score': f1_score(y_true, y_pred),\n",
    "        'ROC-AUC': roc_auc_score(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# Majority voting\n",
    "test_df['ensemble_vote'] = (test_df[['xg_distil_bert', 'xg_sen_transformer', 'nn_prediction']].mean(axis=1) > 0.5).astype(int)\n",
    "\n",
    "# Evaluate ensemble performance\n",
    "ensemble_metrics = calculate_metrics(test_df['actual'], test_df['ensemble_vote'])\n",
    "print(\"Ensemble Metrics:\", ensemble_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
